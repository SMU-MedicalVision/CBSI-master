# Welcome to CBSI!
**Contrast-free BBB Status Identification model (CBSI)** is a generative diffusion AI that can identify BBB status with high accuracy using non-contrast MR images, including T1 and T2-FLAIR MR scans.

<img src="https://github.com/Kindyz/CBSI-debug/blob/main/sample_png/Framework.png" width="800px">


This repository contains the code of our paper "Contrast-free identification of glioma blood-brain barrier status via generative diffusion AI and non-contrast MRI".



- ### Example
| Input               |Output 1              |Output 2                        |
|------------------------------|-----------------|-----------------|
|`T1 and T2-FLAIR MR scans` |`T1Gd MR scan` |`BBB status` |
|<img src="https://github.com/Kindyz/CBSI-debug/blob/main/sample_png/T1.png" width="90px"><img src="https://github.com/Kindyz/CBSI-debug/blob/main/sample_png/T2F.png" width="90px">|<img src="https://github.com/Kindyz/CBSI-debug/blob/main/sample_png/Synthetic_T1Gd.png" width="90px">| _Disrupted_|

- ### System Requirements
This code has been tested on Ubuntu in PyTorch and an NVIDIA GeForce RTX 3090 GPU and an NVIDIA GeForce RTX 2080 Ti GPU.

# 1. Setup Environment
In order to run our model, we suggest you create a virtual environment
```
conda create -n CBSI_env python=3.8
```
and activate it with
```
conda activate CBSI_env
```
Subsequently, download and install the required libraries by running:
```
pip install torch==2.0.0+cu118 torchvision==0.15.1+cu118 -f https://download.pytorch.org/whl/torch_stable.html
pip install -r requirements.txt
```
# 2. Prepare the Dataset
To simplify the dataloading for your own dataset, we provide a default dataset that simply requires the path to the folder with your NifTI images inside, i.e.
```
./Glioma_DATA/RAW_DATA/Train       ./Glioma_DATA/RAW_DATA/Test/         # Path to the folder that contains the images
├── ET-1 	# ET-label          ├── PA_001                          # ID is not important and can be randomly generated to ensure anonymity
│    ├── ID_001                     │        ├── T1.nii.gz              # The sequence of the NifTI (strictly consistent)
│    │       ├── T1C.nii.gz         │        ├── T2F.nii.gz       
│    │       ├── T1.nii.gz          │        └── ROI.nii.gz 
│    │       ├── T2F.nii.gz         ├── PA_002
│    │       └── ROI.nii.gz         │        ├── T1.nii.gz     
│    │       (Generated by BET)     │        ├── ...      
│    ├── ID_002                     ├── ... 
│    ├──...                         └── PA_N
│    └── ID_N 
│
└── ET-0 
     ├── ID_100 
     ├── ID_101  
     ├──...              
     └── ID_M 	
         
#  './Glioma_DATA/RAW_DATA/Val'  has the same format as './Glioma_DATA/RAW_DATA/Train'      
```
If needed, you may consider downloading the glioma public dataset from [Glioma data](https://www.kaggle.com/datasets/kaiyiyi/glioma-data-tcia/) or [BraTS 2023 Challenge](https://www.synapse.org/Synapse:syn51156910/wiki/).

Before training, the data needs to be preprocessed by **'Grayscale Normalization'** and mapped to the range of 0 to 255 by executing the following command.
```
python ./preprocess/Preprocess_grayscale_norm.py --override
```


# 3. Training
- ## Quick Test (optional)
**Stage I**: Synthesis quick test
```
python ./main/train_CBSI_gen.py --gpu 0 --quick_test
```
**Stage II**: Identification quick test 
```
python ./main/train_CBSI_ide.py --gpu 0 --quick_test --gen_save_dir ./main/trained_models/CBSI_gen/{pred_*_...class_seg_time}/  
```
>{} should be changed to the actual path for saving the synthesis result.  
>>e.g., --gen_save_dir ./main/trained_models/CBSI_gen/pred_x0_simple_unet_Improved_32_class_l1_condition_act_tanh_bs2_epoch10_gae1_seed42_class_seg_Jul01_00-00-00/'

>result saving path
>>CBSI_gen:   ./main/trained_models/CBSI_gen/`pred_*_...class_seg_time`/prediction_ddim_10/  
CBSI_ide:   ./main/trained_models/CBSI_ide/`bs*_ImageSize*_epoch*_seed*_time`/prediction/  

**Inference**(optional): quick test. After the training is completed, the inference will be automatically carried out. If you want to perform the inference separately, please run:
```
python ./main/train_CBSI_gen.py --gpu 0 --quick_test --inference_only --save_dir ./main/trained_models/CBSI_gen/{pred_*_...class_seg_time}/
python ./main/train_CBSI_ide.py --gpu 0 --quick_test --inference_only --gen_save_dir ./main/trained_models/CBSI_gen/{pred_*_...class_seg_time}/ --save_dir ./main/trained_models/CBSI_ide/{bs*_ImageSize*_epoch*_seed*_time}/
```
> e.g., --save_dir ./main/trained_models/CBSI_ide/bs1_ImageSize424_epoch10_seed42_Jul01_00-00-00/'
- ## Comprehensive Training

**Stage I**: First, you need to train the conditional diffusion model. To do so in a prepared dataset, you can run the following command:
```
python ./main/train_CBSI_gen.py --gpu 0
```
**Stage II**: Second, you need to train the identification model by running the following command. 
```
python ./main/train_CBSI_ide.py --gpu 0 --gen_save_dir ./main/trained_models/CBSI_gen/{pred_*_...class_seg_time}/
```
>Note that you need to provide the path to the synthesis result (e.g., `--gen_save_dir './main/trained_models/CBSI_gen/pred_x0_simple_unet_Improved_32_class_l1_condition_act_tanh_bs2_epoch10_gae1_seed42_class_seg_Jul01_00-00-00/'`) to successfully run the command.


- ## Visualize the Training Process (optional)
You can use the following command to observe the loss curve of the training process, visualize the sample image, etc.
```
tensorboard --logdir ./main/trained_models/
```
<img src="https://github.com/Kindyz/CBSI-debug/blob/main/sample_png/Tensorboard.png" width="300px">




[Supplement] Problem troubleshooting can be found in Error_troubleshooting.txt
# 4. Inference (optional)
After the training is completed, the inference will be automatically carried out. If you want to perform the inference separately, please run:
```
python ./main/train_CBSI_gen.py --gpu 0 --inference_only --save_dir ./main/trained_models/CBSI_gen/{pred_*_...class_seg_time}/
python ./main/train_CBSI_ide.py --gpu 0 --inference_only --gen_save_dir ./main/trained_models/CBSI_gen/{pred_*_...class_seg_time}/ --save_dir ./main/trained_models/CBSI_ide/{bs*_ImageSize*_epoch*_seed*_time}/
```

# CPU support
This code runs on the CPU automatically when no GPU is available.
Recommended only for quick testing, as CPU processing will be quite time‑consuming, especially for training or inference with diffusion models.


# Citation

To cite our work, please use
```
(To be updated)
```